{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance-Recommendation-Challenge-Solution"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: Run on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CatBoost\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:03.461280Z",
     "start_time": "2020-08-07T19:29:03.186558Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3arOHSJwCtNq"
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd, os, gc\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import roc_curve, auc, log_loss\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedKFold, train_test_split, GroupKFold\n",
    "from catboost import CatBoostClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:03.664112Z",
     "start_time": "2020-08-07T19:29:03.501157Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "s3ZCXtzKDiDe"
   },
   "outputs": [],
   "source": [
    "# Load data from Drive\n",
    "\n",
    "# specify data path\n",
    "path = '/content/drive/MyDrive/COLAB/DATASETS/Zimnat Insurance Competition'\n",
    "\n",
    "train = pd.read_csv(path + '/Train.csv')\n",
    "test = pd.read_csv(path + '/Test.csv')\n",
    "sub = pd.read_csv(path + '/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_train=list(set(train['occupation_code'].unique().tolist())-set(test['occupation_code']))\n",
    "replace_test=list(set(test['occupation_code'].unique().tolist())-set(train['occupation_code']))\n",
    "\n",
    "train['occupation_code']=train['occupation_code'].replace(replace_train,np.nan)\n",
    "test['occupation_code']=test['occupation_code'].replace(replace_test,np.nan)\n",
    "train['occupation_code'].fillna(train['occupation_category_code'],inplace=True)\n",
    "test['occupation_code'].fillna(test['occupation_category_code'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding amount of purchased products for each client(for test without 1 missing)\n",
    "train['sum'] = train.iloc[:, 8:].T.sum()\n",
    "test['sum'] = test.iloc[:, 8:].T.sum()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.marital_status == 'f', 'marital_status'] = 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming features to prevent any repeating\n",
    "train['sex'] += '_sex'\n",
    "train['marital_status'] += '_marital_status'\n",
    "train['branch_code'] += '_branch_code'\n",
    "train['occupation_code'] += '_occupation_code'\n",
    "train['occupation_category_code'] += '_occupation_category_code'\n",
    "test['sex'] += '_sex'\n",
    "test['marital_status'] += '_marital_status'\n",
    "test['branch_code'] += '_branch_code'\n",
    "test['occupation_code'] += '_occupation_code'\n",
    "test['occupation_category_code'] += '_occupation_category_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_products = [\n",
    "    'P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ',\n",
    "    'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D',\n",
    "    'J9JW', 'GHYX', 'ECY3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:05.039157Z",
     "start_time": "2020-08-07T19:29:04.237473Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "oxjj_QAfEyZw"
   },
   "outputs": [],
   "source": [
    "# Make spliting train clients info. Trying to reproduce the situation with test\n",
    "X_train = []\n",
    "X_train_columns = train.columns[:-1]\n",
    "df_train_true = []\n",
    "client_index = 0\n",
    "\n",
    "for line in tqdm_notebook(train.values):\n",
    "\n",
    "    info = line[:8]\n",
    "    info_products = line[8:-1]\n",
    "    indexes = [k for k, i in enumerate(info_products) if i == 1]\n",
    "\n",
    "    for i in indexes:\n",
    "\n",
    "        client_index += 1\n",
    "\n",
    "        for k in range(len(info_products)):\n",
    "\n",
    "            if k == i:\n",
    "\n",
    "                info_products_transformed = list(copy.copy(info_products))\n",
    "                df_train_true.append(info_products)\n",
    "                info_products_transformed[i] = 0\n",
    "\n",
    "                X_train.append(\n",
    "                    list(info) + info_products_transformed +\n",
    "                    [X_train_columns[8 + k]] + [client_index])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "df_train_true = pd.DataFrame(df_train_true)\n",
    "df_train_true.columns = [\n",
    "    'P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ',\n",
    "    'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D',\n",
    "    'J9JW', 'GHYX', 'ECY3'\n",
    "]\n",
    "X_train.columns = [\n",
    "    'ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "    'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "    '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "    'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3',\n",
    "    'product_pred', 'ID2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:10.768064Z",
     "start_time": "2020-08-07T19:29:10.494815Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "URdSMgJeOnLE"
   },
   "outputs": [],
   "source": [
    "# Make info about true values in data of predictions\n",
    "X_test = []\n",
    "true_values = []\n",
    "client_index = 0\n",
    "for line in tqdm_notebook(test.values):\n",
    "\n",
    "    client_index += 1\n",
    "\n",
    "    info = line[:8]\n",
    "    info_products = line[8:-1]\n",
    "    indexes = [k for k, i in enumerate(info_products) if i == 1]\n",
    "\n",
    "    X_test.append(list(info) + list(info_products) + [client_index])\n",
    "\n",
    "    for true in test.columns[8:][indexes]:\n",
    "        true_values.append(line[0] + ' X ' + true)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = [\n",
    "    'ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "    'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n",
    "    '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n",
    "    'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3',\n",
    "    'ID2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:11.136106Z",
     "start_time": "2020-08-07T19:29:11.129621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking shapes\n",
    "train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:07.853673Z",
     "start_time": "2020-08-07T19:29:07.785086Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:12.081590Z",
     "start_time": "2020-08-07T19:29:12.053903Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1KcI9I6g1de"
   },
   "source": [
    "## Reshaping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:13.305572Z",
     "start_time": "2020-08-07T19:29:13.262176Z"
    },
    "code_folding": [],
    "colab": {},
    "colab_type": "code",
    "id": "ttUKNdnAczTd"
   },
   "outputs": [],
   "source": [
    "# Make data with reshape\n",
    "features_train = []\n",
    "features_test = []\n",
    "columns = []\n",
    "\n",
    "append_features = [\n",
    "    'P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ',\n",
    "    'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D',\n",
    "    'J9JW', 'GHYX', 'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status',\n",
    "    'branch_code', 'occupation_code', 'occupation_category_code', 'birth_year'\n",
    "]\n",
    "for f in append_features:\n",
    "\n",
    "    features_train.append(X_train[f].values.reshape(-1, 1))\n",
    "    features_test.append(X_test[f].values.reshape(-1, 1))\n",
    "\n",
    "    columns.append(np.array([f]))\n",
    "\n",
    "y_train = X_train[['product_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:13.988566Z",
     "start_time": "2020-08-07T19:29:13.870945Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kWCK5LrfkPp-"
   },
   "outputs": [],
   "source": [
    "features_train = np.concatenate(features_train, axis=1)\n",
    "features_test = np.concatenate(features_test, axis=1)\n",
    "columns = np.concatenate(np.array(columns))\n",
    "\n",
    "X_train = pd.DataFrame(features_train)\n",
    "X_train.columns = columns\n",
    "\n",
    "X_test = pd.DataFrame(features_test)\n",
    "X_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YVUKKo3llI0y"
   },
   "source": [
    "## Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:29:17.239570Z",
     "start_time": "2020-08-07T19:29:16.140241Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "NhfA7yullH76"
   },
   "outputs": [],
   "source": [
    "# Reformatting date of join to some features: year, month, day, day of week, day of year of join; add age of clients\n",
    "for df in [X_train, X_test]:\n",
    "    df['join_date'] = pd.to_datetime(df.join_date, format='%d/%m/%Y')\n",
    "\n",
    "    df['from_begin'] = (df.join_date - pd.datetime(2010, 1, 1)).dt.days\n",
    "\n",
    "    df['join_day'] = df['join_date'].dt.day\n",
    "    df['join_month'] = df['join_date'].dt.month\n",
    "    df['join_year'] = df['join_date'].dt.year\n",
    "    df['dayofweek'] = df['join_date'].dt.weekday\n",
    "    df['day_of_year'] = df['join_date'].dt.dayofyear\n",
    "\n",
    "    df['age'] = (df['join_year'] - df['birth_year']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T19:31:04.854098Z",
     "start_time": "2020-08-07T19:31:04.805496Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Concating train and test data\n",
    "common = X_train.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common['branch_start']=pd.datetime.now().year-common.groupby('branch_code')['join_year'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, row):\n",
    "    df[row[0]]=common.groupby(row[1])[row[2]].transform(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_features = [['nuniq_people', 'branch_code', 'ID', 'nunique'],\n",
    "                ['nuniq_branch_in_year', 'join_year', 'branch_code', 'nunique'], \n",
    "                ['nuniq_year', 'branch_code', 'join_year', 'nunique'], \n",
    "                ['nuniq_month', 'branch_code', 'join_month', 'nunique'], \n",
    "                ['mean_age_in_branch', 'branch_code', 'age', 'mean'],\n",
    "                ['std_age_in_branch', 'branch_code', 'age', 'std'],\n",
    "                ['median_age_in_branch', 'branch_code', 'age', 'median'],\n",
    "                ['mean_age_in_occupation', 'occupation_code', 'age', 'mean'],\n",
    "                ['std_age_in_occupation', 'occupation_code', 'age', 'std'],\n",
    "                ['median_age_in_occupation', 'occupation_code', 'age', 'median']]\n",
    "for row in row_features:\n",
    "    transform(common,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common['birth_year_binary']= pd.cut(common['birth_year'], bins=5)\n",
    "\n",
    "common['branch_ocupation']=common['branch_code']+'_'+common['occupation_code']\n",
    "common['branch_ocupcode']=common['branch_code']+'_'+common['occupation_category_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common['Number_of_Insurance_Bought']=common.iloc[:, :21].sum(axis=1)\n",
    "\n",
    "def mapper(common):\n",
    "    if common['Number_of_Insurance_Bought']==1:\n",
    "        return 'One'\n",
    "    elif (common['Number_of_Insurance_Bought']>1) & (common['Number_of_Insurance_Bought']<5):\n",
    "        return 'Medium'\n",
    "    elif (common['Number_of_Insurance_Bought']>4 )& (common['Number_of_Insurance_Bought']<8):\n",
    "        return 'High'    \n",
    "    else:\n",
    "        return 'Too High'   \n",
    "common['Insurance_Count']=common.apply(lambda common:mapper(common) ,axis = 1)\n",
    "del common['Number_of_Insurance_Bought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [\n",
    "        'sex', 'marital_status', 'occupation_code', 'occupation_category_code',\n",
    "        'birth_year_binary', 'branch_ocupation', 'branch_ocupcode', 'Insurance_Count'\n",
    "]:\n",
    "    freq = (common.groupby(name).size()) / len(common)\n",
    "    common[name + '_freq'] = common[name].apply(lambda x: freq[x])\n",
    "    common[name + '_freq'] = common[name + '_freq'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_ins = LabelEncoder()\n",
    "common['Insurance_Count'] = le_ins.fit_transform(common['Insurance_Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in tqdm_notebook(common.iterrows()):\n",
    "    res = []\n",
    "    for c in names_products:\n",
    "        if row[c] == 1:\n",
    "            res.append(c)\n",
    "    common.loc[common.index == i, 'product_comb'] = '_'.join(sorted(res))\n",
    "common['product_comb'] = le_ins.fit_transform(common['product_comb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm_notebook(names_products):\n",
    "    for cols in names_products:\n",
    "        if col!=cols:\n",
    "            common[col+'_'+cols]=common.groupby(col)[cols].transform(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.drop(\n",
    "    columns=['birth_year_binary', 'branch_ocupation', 'branch_ocupcode'],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Approximate counting of days after open branches and after first buy of each product\n",
    "for code in tqdm_notebook(common.branch_code.unique()):\n",
    "    common.loc[common.branch_code == code, 'from_arise_branch'] = \\\n",
    "    common.loc[common.branch_code == code, 'from_begin'] - common.loc[common.branch_code == code, 'from_begin'].min()\n",
    "    for product in names_products:\n",
    "        common.loc[common.branch_code == code, 'from_arise_product_'+product+'_in_branch'] = \\\n",
    "        common.loc[common.branch_code == code, 'from_begin'] - common.loc[(common.branch_code == code)&(common[product]==1), 'from_begin'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for product in tqdm_notebook(names_products):\n",
    "    common['from_arise_product_'+product] = (common['join_date'] - common.loc[common[product] == 1, 'join_date'].min()).dt.days\n",
    "    common[product+'_'+'sum_in_branch']=common.groupby('branch_code')[product].transform(sum)\n",
    "    common[product+'_'+'_age_mean']=common.groupby(product)['age'].transform('mean')\n",
    "    common[product+'_'+'_age_std']=common.groupby(product)['age'].transform('std')\n",
    "    common[product+'_'+'_age_median']=common.groupby(product)['age'].transform('median')\n",
    "    common[product+'_'+'_sum_join_year']=common.groupby('join_year')[product].transform(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting concating data to train and test\n",
    "X_train = common[:66353]\n",
    "X_test = common[66353:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDTy7qyulLoP"
   },
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding of target values that look like names of missing products\n",
    "#\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train.iloc[:, 0])\n",
    "\n",
    "y_train = pd.DataFrame(le.transform(y_train.iloc[:, 0]))\n",
    "y_train.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Merging amount of purchased products\n",
    "#\n",
    "X_train = X_train.merge(train[['ID', 'sum']])\n",
    "X_test = X_test.merge(test[['ID', 'sum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Adding features with replacing to string type to use them like cat_features\n",
    "#\n",
    "for df in [X_train, X_test]:\n",
    "    df['dayofweek_cat'] = df['dayofweek'].astype(str)\n",
    "    df['from_begin_cat'] = df['from_begin'].astype(str)\n",
    "    df['birth_year'] = df['birth_year'].astype(str)\n",
    "    df['join_year_cat'] = df['join_year'].astype(str)\n",
    "    df['sum_cat'] = df['sum'].astype(str)\n",
    "    df['day_of_year_cat'] = df['day_of_year'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qn9zHq0iqhA3"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "cat_features = ['sex','marital_status','branch_code','occupation_category_code','occupation_code','dayofweek_cat','from_begin_cat',\\\n",
    "                'sum_cat','birth_year','join_year_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cat = CatBoostClassifier(depth = 5, n_estimators = 15000, learning_rate = 0.01, random_state = 567, task_type = 'GPU', \\\n",
    "                               thread_count = 1, verbose = 100, use_best_model = True, nan_mode = 'Max')\n",
    "\n",
    "probs = []\n",
    "probs_train = []\n",
    "i = 1\n",
    "scoring = 0\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "cols = X_train.drop(columns=['ID', 'ID2', 'join_date']).columns\n",
    "for train_index, test_index in group_kfold.split(X_train, y_train,\n",
    "                                                 np.array(X_train['ID'])):\n",
    "    X_real_train, X_valid = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_real_train, y_valid = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    print('Fold', i)\n",
    "    model_cat.fit(\n",
    "        X_real_train[cols],\n",
    "        y_real_train,\n",
    "        cat_features=cat_features,\n",
    "        eval_set=[(X_valid[cols], y_valid)],\n",
    "        early_stopping_rounds = 200,\n",
    "    )\n",
    "    scoring += model_cat.get_best_score()['validation']['MultiClass']\n",
    "\n",
    "    proba = model_cat.predict_proba(X_test[cols])\n",
    "    probs.append(proba)\n",
    "    probs_train.append(model_cat.predict_proba(X_train[cols]))\n",
    "    i += 1\n",
    "scoring /= 5\n",
    "print('MEAN SCORE =', scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(model_cat.feature_importances_,\n",
    "                     index=cols,\n",
    "                     columns=['importance']).query('importance>1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Meaning predict values\n",
    "new_a = np.ones((10000,21)) * 0.0\n",
    "for r in probs:\n",
    "    new_a += r\n",
    "new_a /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(new_a)\n",
    "y_test.columns = le.inverse_transform(y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for i,row in tqdm_notebook(X_test.iterrows()):\n",
    "    summ = 0\n",
    "    \n",
    "    for c in names_products:\n",
    "        if row[c] == 1:\n",
    "            y_test.loc[y_test.index == i, c] = 1.0\n",
    "        else:\n",
    "            summ += y_test.loc[y_test.index == i, c].values[0]\n",
    "    for c in names_products:\n",
    "        if row[c] != 1.0:\n",
    "            y_test.loc[y_test.index == i, c] /= summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformating predicted value\n",
    "answer_mass = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    id = X_test['ID'].iloc[i]\n",
    "    for c in y_test.columns:\n",
    "        answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n",
    "\n",
    "df_answer = pd.DataFrame(answer_mass)\n",
    "df_answer.columns = ['ID X PCODE', 'Label']\n",
    "df_answer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit\n",
    "df_answer.to_csv('submis_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public leaderboard -> 0.027052459 <br>\n",
    "Private Leaderboard -> 0.026766397"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Baseline1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "142px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "220.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
